import streamlit as st
import os
import re
import urllib.parse
import random
import time
from typing import List, Set, Tuple
import pandas as pd
import requests
from bs4 import BeautifulSoup
from ddgs import DDGS
import cloudscraper

# ---------------------------
# Configura√ß√£o Inicial
# ---------------------------
st.set_page_config(
    page_title="Responde AI TOTVS",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Headers melhorados para evitar 403
DEFAULT_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
    'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',
    'Accept-Encoding': 'gzip, deflate, br',
    'Referer': 'https://centraldeatendimento.totvs.com/',
    'Sec-Ch-Ua': '"Google Chrome";v="123", "Not:A-Brand";v="8", "Chromium";v="123"',
    'Sec-Ch-Ua-Mobile': '?0',
    'Sec-Ch-Ua-Platform': '"Windows"',
    'Sec-Fetch-Dest': 'document',
    'Sec-Fetch-Mode': 'navigate',
    'Sec-Fetch-Site': 'same-origin',
    'Upgrade-Insecure-Requests': '1',
    'DNT': '1'
}

# Lista de User-Agents alternativos
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'
]

# Inicializar scraper com configura√ß√µes melhoradas
scraper = cloudscraper.create_scraper(
    browser={
        'browser': 'chrome',
        'platform': 'windows',
        'mobile': False
    }
)

# ---------------------------
# Stop words e pr√©-processamento
# ---------------------------
STOP_WORDS = {
    "bom dia", "boa tarde", "boa noite", "ol√°", "att", "atenciosamente",
    "cumprimentos", "obrigado", "obrigada", "prezado", "prezada",
    "caro", "cara", "senhor", "senhora", "ola", "oi", "sauda√ß√µes",
    "tudo bem", "tudo bem?", "amigo", "amiga", "por favor",
    "grato", "grata", "cordialmente", "abra√ßo", "abs"
}

def clean_query(query: str) -> str:
    if not query:
        return ""
    query = re.sub(r'[\u0080-\uFFFF]', '', query)
    query = query.lower().strip()
    for stop in STOP_WORDS:
        if query.startswith(stop):
            query = query[len(stop):].strip()
        if query.endswith(stop):
            query = query[:-len(stop)].strip()
    query = re.sub(r'[^\w\s√°√†√¢√£√©√®√™√≠√Ø√≥√¥√µ√∂√∫√ß√±-]', ' ', query)
    query = re.sub(r'\s+', ' ', query).strip()
    parts = query.split()
    keep = []
    for p in parts:
        if len(p) >= 3 or p in ['erp', 'sql', 'api', 'xml', 'json', 'tss', 'nt', 'danfe']:
            keep.append(p)
    return " ".join(keep)

def clean_text(text: str) -> str:
    if not text or pd.isna(text):
        return ""
    text = text.replace("\0", " ")
    text = re.sub(r'Anexo\(s\):.*', '', text, flags=re.DOTALL)
    text = re.sub(r'<[^>]*>', ' ', text)
    text = re.sub(r'\\\w+', ' ', text)
    text = re.sub(r'\bhttps?://\S+\b', '', text)
    text = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,7}\b', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def tem_video_ou_anexo(query: str) -> bool:
    padroes = [
        r"\banexo\b", r"\banexos\b", r"\banexado\b", r"\banexada\b",
        r"\bv[√≠i]deo\b", r"\bv[√≠i]deos\b", r"\bgrava√ß[√£a]o\b",
        r"\bprint\b", r"\bimagem\b", r"\bscreenshot\b"
    ]
    for p in padroes:
        if re.search(p, query.lower()):
            return True
    return False

def get_headers_with_random_ua():
    """Retorna headers com User-Agent aleat√≥rio"""
    headers = DEFAULT_HEADERS.copy()
    headers['User-Agent'] = random.choice(USER_AGENTS)
    return headers

def pesquisar_interna_totvs(query: str, limit: int = 5) -> List[str]:
    base = "https://centraldeatendimento.totvs.com"
    search_url = f"{base}/hc/pt-br/search?query={urllib.parse.quote(query)}"
    
    links = []
    try:
        headers = get_headers_with_random_ua()
        resp = scraper.get(search_url, headers=headers, timeout=20)
        
        if resp.status_code == 403:
            st.warning("‚ö†Ô∏è Acesso bloqueado temporariamente. Tentando abordagem alternativa...")
            # Tentar com requests diretamente
            resp = requests.get(search_url, headers=headers, timeout=20)
        
        resp.raise_for_status()
        soup = BeautifulSoup(resp.content, "html.parser")
        
        for a in soup.select("a[href*='/articles/']"):
            href = a.get("href")
            if not href:
                continue
            if href.startswith("/"):
                href = base + href
            if href.startswith(base) and href not in links:
                links.append(href)
            if len(links) >= limit:
                break
                
    except requests.HTTPError as e:
        if e.response.status_code == 403:
            st.error(f"‚ùå Acesso negado (403) para a pesquisa. Tente novamente em alguns instantes.")
        else:
            st.error(f"Erro HTTP {e.response.status_code} na pesquisa interna")
    except Exception as e:
        st.error(f"Erro na pesquisa interna: {e}")
        
    return links

def buscar_documentacao_totvs(query: str, max_links: int = 5) -> List[str]:
    """Busca links na documenta√ß√£o TOTVS - aumentado para 5 links para ter mais op√ß√µes"""
    cleaned = clean_query(query) or query
    if "Protheus" not in cleaned.lower():
        search_query = f"site:centraldeatendimento.totvs.com Protheus {cleaned}"
    else:
        search_query = f"site:centraldeatendimento.totvs.com {cleaned}"
        
    found: List[str] = []
    seen: Set[str] = set()
    
    try:
        with DDGS() as ddgs:
            for r in ddgs.text(search_query, max_results=25):  # Aumentado para 25
                url = r.get("href", "")
                if url.startswith("https://centraldeatendimento.totvs.com") and "/articles/" in url:
                    if url not in seen:
                        found.append(url)
                        seen.add(url)
                if len(found) >= max_links:
                    break
    except Exception as e:
        st.error(f"Erro no DuckDuckGo: {e}")

    # Se n√£o encontrou links suficientes, tentar pesquisa interna
    if len(found) < max_links:
        interna = pesquisar_interna_totvs(cleaned, limit=max_links)
        for url in interna:
            if url.startswith("https://centraldeatendimento.totvs.com") and url not in seen:
                found.append(url)
                seen.add(url)
            if len(found) >= max_links:
                break

    if not found:
        return [f"https://centraldeatendimento.totvs.com/hc/pt-br/search?query={urllib.parse.quote(cleaned)}"]

    return found[:max_links]

def extrair_conteudo_pagina(url: str) -> str:
    if '/search?' in url:
        return "P√°gina de pesquisa - conte√∫do n√£o extra√≠do"

    try:
        # Primeira tentativa: cloudscraper com headers melhorados
        headers = get_headers_with_random_ua()
        
        # Pequena pausa aleat√≥ria para evitar detec√ß√£o
        time.sleep(random.uniform(1, 3))
        
        resp = scraper.get(url, headers=headers, timeout=20)
        
        # Se der 403, tentar com requests + headers alternativos
        if resp.status_code == 403:
            st.warning(f"‚ö†Ô∏è Cloudscraper bloqueado para {url}. Tentando abordagem alternativa...")
            
            # Tentar com requests e headers diferentes
            alt_headers = headers.copy()
            alt_headers['User-Agent'] = random.choice(USER_AGENTS)
            
            resp = requests.get(url, headers=alt_headers, timeout=20)
            
            if resp.status_code == 403:
                st.error(f"‚ùå Acesso negado para: {url}")
                return "Conte√∫do n√£o acess√≠vel - erro 403 Forbidden"
        
        resp.raise_for_status()
        
        soup = BeautifulSoup(resp.content, 'html.parser')
        
        # Remover elementos desnecess√°rios
        for el in soup(['script', 'style', 'nav', 'footer', 'header', 'aside', 'form']):
            el.decompose()
            
        # Tentar encontrar o conte√∫do principal
        content = (soup.select_one("article") or 
                  soup.select_one("main") or 
                  soup.select_one(".article-body") or
                  soup.select_one(".article-content") or
                  soup.select_one(".content"))
        
        if content:
            # Remover elementos espec√≠ficos do help center
            for el in content.select('.article-attachments, .article-meta, .article-votes, .article-info, .comments'):
                el.decompose()
            text = content.get_text(separator=' ', strip=True)
        else:
            # Fallback: pegar todo o texto
            text = soup.get_text(separator=' ', strip=True)
            
        return clean_text(text)[:6000]
        
    except requests.HTTPError as e:
        if e.response.status_code == 403:
            return f"Erro 403 - Acesso negado: {url}"
        elif e.response.status_code == 404:
            return f"Erro 404 - P√°gina n√£o encontrada: {url}"
        else:
            return f"Erro HTTP {e.response.status_code} ao acessar: {url}"
    except Exception as e:
        return f"Erro ao extrair conte√∫do: {str(e)}"

def pontuar_relevancia(texto: str, query: str) -> float:
    tokens_query = set(clean_query(query).split())
    tokens_texto = set(texto.lower().split())
    if not tokens_query or not tokens_texto:
        return 0.0
    return len(tokens_query & tokens_texto) / len(tokens_query)

def reclassificar_artigos_ia(artigos: List[Tuple[float, str, str]], query: str, use_gemini: bool, api_key: str, modelo: str) -> List[Tuple[float, str, str]]:
    """Usa IA para reclassificar os artigos por relev√¢ncia"""
    if not artigos:
        return artigos
    
    try:
        # Preparar dados dos artigos para a IA
        artigos_info = []
        for score, url, conteudo in artigos:
            # Extrair t√≠tulo do URL ou usar trecho do conte√∫do
            titulo = url.split('/')[-1].replace('-', ' ')[:100]
            if conteudo and len(conteudo) > 50:
                preview = conteudo[:200] + "..."
            else:
                preview = "Conte√∫do n√£o dispon√≠vel"
            artigos_info.append(f"URL: {url}\nT√≠tulo: {titulo}\nPreview: {preview}\n---")
        
        artigos_texto = "\n".join(artigos_info)
        
        if use_gemini:
            resposta = reclassificar_gemini(query, artigos_texto, modelo, api_key)
        else:
            resposta = reclassificar_openai(query, artigos_texto, modelo, api_key)
        
        # Processar resposta da IA para extrair ordena√ß√£o
        artigos_ordenados = processar_resposta_reclassificacao(resposta, artigos)
        
        if artigos_ordenados:
            return artigos_ordenados
        else:
            # Fallback: ordena√ß√£o original por score
            return sorted(artigos, reverse=True, key=lambda x: x[0])
            
    except Exception as e:
        st.error(f"Erro na reclassifica√ß√£o por IA: {e}")
        # Fallback para ordena√ß√£o por score b√°sico
        return sorted(artigos, reverse=True, key=lambda x: x[0])

def reclassificar_gemini(query: str, artigos_texto: str, model: str, api_key: str) -> str:
    """Reclassifica artigos usando Gemini"""
    import google.generativeai as genai
    genai.configure(api_key=api_key)
    
    prompt = f"""
    Analise estes artigos da documenta√ß√£o TOTVS e ordene-os por relev√¢ncia para a pergunta do usu√°rio.
    
    PERGUNTA DO USU√ÅRIO: {query}
    
    ARTIGOS ENCONTRADOS:
    {artigos_texto}
    
    INSTRU√á√ïES:
    1. Analise cada artigo em rela√ß√£o √† pergunta
    2. Ordene do MAIS RELEVANTE para o MENOS RELEVANTE
    3. Retorne APENAS os URLs em ordem de relev√¢ncia, um por linha
    4. N√£o inclua explica√ß√µes, apenas a lista ordenada de URLs
    
    URLs ORDENADOS:
    """
    
    try:
        gemini_model = genai.GenerativeModel(model_name=model)
        response = gemini_model.generate_content([prompt])
        return response.text.strip()
    except Exception as e:
        raise Exception(f"Erro Gemini: {e}")

def reclassificar_openai(query: str, artigos_texto: str, model: str, api_key: str) -> str:
    """Reclassifica artigos usando OpenAI"""
    from openai import OpenAI
    client = OpenAI(api_key=api_key)
    
    prompt = f"""
    Analise estes artigos da documenta√ß√£o TOTVS e ordene-os por relev√¢ncia para a pergunta do usu√°rio.
    
    PERGUNTA DO USU√ÅRIO: {query}
    
    ARTIGOS ENCONTRADOS:
    {artigos_texto}
    
    INSTRU√á√ïES:
    1. Analise cada artigo em rela√ß√£o √† pergunta
    2. Ordene do MAIS RELEVANTE para o MENOS RELEVANTE
    3. Retorne APENAS os URLs em ordem de relev√¢ncia, um por linha
    4. N√£o inclua explica√ß√µes, apenas a lista ordenada de URLs
    """
    
    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "Voc√™ √© um especialista em classificar documenta√ß√£o t√©cnica por relev√¢ncia."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.0,
            max_tokens=500,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        raise Exception(f"Erro OpenAI: {e}")

def processar_resposta_reclassificacao(resposta_ia: str, artigos_originais: List[Tuple[float, str, str]]) -> List[Tuple[float, str, str]]:
    """Processa a resposta da IA e reordena os artigos"""
    if not resposta_ia:
        return []
    
    # Extrair URLs da resposta
    urls_ordenados = []
    for linha in resposta_ia.split('\n'):
        linha = linha.strip()
        if linha.startswith('http'):
            urls_ordenados.append(linha)
    
    # Criar mapa de artigos por URL
    artigo_por_url = {url: (score, url, conteudo) for score, url, conteudo in artigos_originais}
    
    # Reordenar baseado na classifica√ß√£o da IA
    artigos_ordenados = []
    for url in urls_ordenados:
        if url in artigo_por_url:
            artigos_ordenados.append(artigo_por_url[url])
    
    # Adicionar quaisquer artigos que n√£o foram classificados pela IA
    urls_adicionados = set(urls_ordenados)
    for artigo in artigos_originais:
        if artigo[1] not in urls_adicionados:
            artigos_ordenados.append(artigo)
    
    return artigos_ordenados

def formatar_links_saiba_mais(links: List[str]) -> str:
    """Formata os links para a se√ß√£o Saiba Mais"""
    if not links:
        return ""
    
    padroes_de_remocao = ["-Cross", "-CROSS", "-RH", "-MP", "-Log√≠stica", "-Framework", "-LOG", "-FIN", "-FAT", "-CRM"]
    
    links_formatados = []
    for link in links:
        link_limpo = link
        for padrao in padroes_de_remocao:
            posicao = link.find(padrao)
            if posicao != -1:
                link_limpo = link[:posicao]
                break
        links_formatados.append(link_limpo)
    
    # Remover duplicatas mantendo a ordem
    links_unicos = []
    for link in links_formatados:
        if link not in links_unicos:
            links_unicos.append(link)
    
    # Formatar a se√ß√£o Saiba Mais
    saiba_mais = "\n\n**üîó Saiba mais:**\n"
    for i, link in enumerate(links_unicos[:5], 1):  # Limitar a 5 links
        saiba_mais += f"{i}. {link}\n"
    
    return saiba_mais

def get_ai_response(query: str, context: str, fontes: List[str], modelo: str, use_gemini: bool, api_key: str, temperatura: float):
    """Fun√ß√£o unificada que escolhe entre Gemini e ChatGPT"""
    
    # Filtrar contexto removendo mensagens de erro
    if "erro 403" in context.lower() or "acesso negado" in context.lower():
        context = "Conte√∫do n√£o dispon√≠vel devido a restri√ß√µes de acesso."
    
    if not context or not context.strip() or context == "Conte√∫do n√£o dispon√≠vel devido a restri√ß√µes de acesso.":
        return "N√£o encontrei essa informa√ß√£o na documenta√ß√£o oficial devido a restri√ß√µes de acesso."

    if use_gemini:
        return get_gemini_response(query, context, fontes, modelo, api_key, temperatura)
    else:
        return get_chatgpt_response(query, context, fontes, modelo, api_key, temperatura)

def get_gemini_response(query: str, context: str, fontes: List[str], model: str, api_key: str, temperatura: float):
    try:
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        
        # Configurar generation config com temperatura
        generation_config = {
            "temperature": temperatura,
            "top_p": 0.0,
            "top_k": 40,
            "max_output_tokens": 512,
        }
        
        gemini_model = genai.GenerativeModel(
            model_name=model,
            generation_config=generation_config
        )
        
        system_prompt = (
            "Voc√™ √© um analista de suporte especializado no ERP Protheus da TOTVS.\n"
            "Responda de forma t√©cnica, precisa e baseada exclusivamente no contexto fornecido.\n"
            "- Se a informa√ß√£o n√£o estiver no contexto, responda apenas: \"N√£o encontrei essa informa√ß√£o na documenta√ß√£o oficial\".\n"
            "- Seja objetivo e inclua passos acion√°veis quando aplic√°vel.\n"
            "- N√ÉO inclua a se√ß√£o 'Fontes consultadas' no final - isso ser√° adicionado automaticamente.\n"
        )

        user_content = (
            f"{system_prompt}\n\n"
            f"PERGUNTA DO USU√ÅRIO:\n{query}\n\n"
            f"CONTE√öDO EXTRA√çDO:\n{context}\n\n"
            "Fontes dispon√≠veis:\n" + "\n".join(fontes)
        )

        response = gemini_model.generate_content([user_content])
        return response.text.strip()
    except Exception as e:
        return f"Erro ao gerar resposta com Gemini: {e}"

def get_chatgpt_response(query: str, context: str, fontes: List[str], model: str, api_key: str, temperatura: float):
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
        
        system_prompt = (
            "Voc√™ √© um analista de suporte especializado no ERP Protheus da TOTVS.\n"
            "Responda de forma t√©cnica, precisa e baseada exclusivamente no contexto fornecido.\n"
            "- Se a informa√ß√£o n√£o estiver no contexto, responda apenas: \"N√£o encontrei essa informa√ß√£o na documenta√ß√£o oficial\".\n"
            "- Seja objetivo e inclua passos acion√°veis quando aplic√°vel.\n"
            "- N√ÉO inclua a se√ß√£o 'Fontes consultadas' no final - isso ser√° adicionado automaticamente.\n"
        )
        
        user_content = f"PERGUNTA DO USU√ÅRIO:\n{query}\n\nCONTE√öDO EXTRA√çDO:\n{context}\n\nFontes dispon√≠veis:\n" + "\n".join(fontes)

        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content},
            ],
            temperature=temperatura,
            max_tokens=512,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"Erro ao gerar resposta com OpenAI: {e}"

# ---------------------------
# Interface Streamlit
# ---------------------------
def inicializar_session_state():
    """Inicializa as vari√°veis de session state"""
    if 'min_score' not in st.session_state:
        st.session_state.min_score = 0.5
    if 'use_gemini' not in st.session_state:
        st.session_state.use_gemini = True
    if 'modelo' not in st.session_state:
        st.session_state.modelo = "gemini-1.5-flash"
    if 'api_key' not in st.session_state:
        st.session_state.api_key = ""
    if 'temperatura' not in st.session_state:
        st.session_state.temperatura = 0.1
    if 'mostrar_codigo' not in st.session_state:
        st.session_state.mostrar_codigo = False
    if 'reclassificar_ia' not in st.session_state:
        st.session_state.reclassificar_ia = True  # Nova op√ß√£o

def atualizar_lista_modelos():
    """Atualiza a lista de modelos baseado na escolha Gemini/OpenAI"""
    if st.session_state.use_gemini:
        modelos_disponiveis = ["gemini-2.5-pro","gemini-2.5-flash","gemini-2.0-pro","gemini-2.0-flash","gemini-1.5-pro"]
        if not st.session_state.modelo.startswith("gemini"):
            st.session_state.modelo = "gemini-1.5-flash"
    else:
        modelos_disponiveis = ["gpt-5","gpt-5-mini","gpt-5-nano","gpt-4.1","gpt-4.1-mini","gpt-4.1-nano","gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"]
        if not any(model in st.session_state.modelo for model in ["gpt", "openai"]):
            st.session_state.modelo = "gpt-4o-mini"
    return modelos_disponiveis

def processar_pergunta(user_query: str):
    """Processa a pergunta do usu√°rio e retorna a resposta"""
    # Verificar se a API key foi configurada
    if not st.session_state.api_key:
        return "Erro: Chave da API n√£o configurada. Por favor, configure sua chave na sidebar."
    
    cleaned_query = clean_query(user_query)
    if not cleaned_query:
        return "N√£o foi poss√≠vel processar a pergunta."

    if tem_video_ou_anexo(user_query):
        return "Pergunta cont√©m refer√™ncia a v√≠deo ou anexo. N√£o ser√° feita busca autom√°tica na documenta√ß√£o."
    
    try:
        # Buscar links
        with st.status("Buscando na documenta√ß√£o TOTVS...", expanded=True) as status:
            status.write("üîç Procurando artigos relevantes...")
            links = buscar_documentacao_totvs(user_query, max_links=8)  # Buscar mais links
            
            if not links:
                return "N√£o foram encontrados artigos relevantes na documenta√ß√£o TOTVS."
            
            status.write(f"üìö Encontrados {len(links)} artigos. Extraindo conte√∫do...")
            contexto_scores = []
            
            # Extrair conte√∫do dos links
            for i, link in enumerate(links):
                status.write(f"üìñ Lendo artigo {i+1}/{len(links)}...")
                texto = extrair_conteudo_pagina(link)
                score = pontuar_relevancia(texto, user_query)
                contexto_scores.append((score, link, texto))

            # Reclassifica√ß√£o inteligente por IA
            if st.session_state.reclassificar_ia and len(contexto_scores) > 1:
                status.write("üß† Reclassificando artigos por relev√¢ncia...")
                contexto_scores = reclassificar_artigos_ia(
                    contexto_scores, 
                    user_query, 
                    st.session_state.use_gemini,
                    st.session_state.api_key,
                    st.session_state.modelo
                )
            else:
                # Ordena√ß√£o tradicional por score
                contexto_scores.sort(reverse=True, key=lambda x: x[0])
            
            status.write("ü§ñ Gerando resposta com IA...")
            
            # Usar os 3 artigos mais relevantes para o contexto
            artigos_relevantes = contexto_scores[:3]
            contexto_combinado = "\n\n".join([conteudo for _, _, conteudo in artigos_relevantes if conteudo.strip()])
            
            # Gerar resposta
            if not contexto_combinado.strip():
                resposta_final = "Aten√ß√£o: n√£o foi poss√≠vel validar essa informa√ß√£o espec√≠fica na documenta√ß√£o oficial."
            elif contexto_scores[0][0] < st.session_state.min_score:
                resposta_final = "Observa√ß√£o: essa consulta aborda um ponto n√£o detalhado na documenta√ß√£o. A resposta √© baseada em conhecimento geral.\n\n"
                resposta_final += get_ai_response(
                    user_query, 
                    contexto_combinado, 
                    [link for _, link, _ in artigos_relevantes], 
                    st.session_state.modelo,
                    st.session_state.use_gemini,
                    st.session_state.api_key,
                    st.session_state.temperatura
                )
            else:
                resposta_final = get_ai_response(
                    user_query, 
                    contexto_combinado, 
                    [link for _, link, _ in artigos_relevantes], 
                    st.session_state.modelo,
                    st.session_state.use_gemini,
                    st.session_state.api_key,
                    st.session_state.temperatura
                )
            
            # Adicionar se√ß√£o "Saiba mais" se a resposta for v√°lida
            mensagens_erro = [
                "n√£o foi poss√≠vel validar essa informa√ß√£o espec√≠fica",
                "n√£o encontrei essa informa√ß√£o na documenta√ß√£o oficial",
                "conte√∫do n√£o dispon√≠vel devido a restri√ß√µes de acesso"
            ]
            
            resposta_valida = not any(erro in resposta_final.lower() for erro in mensagens_erro)
            
            if resposta_valida and links:
                saiba_mais = formatar_links_saiba_mais([link for _, link, _ in contexto_scores[:5]])  # Top 5 links
                resposta_final += saiba_mais
            
            status.update(label="Processamento completo!", state="complete")
            
        return resposta_final

    except Exception as e:
        return f"Ocorreu um erro durante o processamento: {str(e)}"

def main():
    # Inicializar session state
    inicializar_session_state()
    
    # Sidebar para configura√ß√µes
    with st.sidebar:
        st.header("‚öôÔ∏è Configura√ß√µes")
        
        # Checkbox para escolher entre Gemini e OpenAI
        st.session_state.use_gemini = st.checkbox(
            "Usar Google Gemini",
            value=st.session_state.use_gemini,
            help="Desmarque para usar OpenAI"
        )
        
        # Lista de modelos atualizada
        modelos_disponiveis = atualizar_lista_modelos()
        
        # Configura√ß√µes avan√ßadas
        st.session_state.reclassificar_ia = st.checkbox(
            "üß† Reclassifica√ß√£o Inteligente por IA",
            value=st.session_state.reclassificar_ia,
            help="Usa IA para reordenar artigos por relev√¢ncia (recomendado)"
        )
        
        st.session_state.min_score = st.slider(
            "üéØ Score M√≠nimo de Relev√¢ncia",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.min_score,
            step=0.1,
            help="Quanto maior o score, mais relevante precisa ser o conte√∫do"
        )
        
        st.session_state.temperatura = st.slider(
            "üå°Ô∏è Temperatura da IA",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.temperatura,
            step=0.1,
            help="Valores mais baixos = respostas mais focadas e determin√≠sticas\nValores mais altos = respostas mais criativas e variadas"
        )
        
        # Explica√ß√£o da temperatura
        with st.expander("üí° Sobre a Temperatura"):
            st.markdown("""
            **Como a temperatura afeta as respostas:**
            
            - **0.0 - 0.3**: Respostas muito focadas e consistentes
            - **0.4 - 0.7**: Equil√≠brio entre criatividade e precis√£o  
            - **0.8 - 1.0**: Respostas mais criativas e variadas
            
            *Recomendado: 0.1-0.3 para suporte t√©cnico*
            """)
        
        st.session_state.modelo = st.selectbox(
            "ü§ñ Modelo de IA",
            options=modelos_disponiveis,
            index=modelos_disponiveis.index(st.session_state.modelo) if st.session_state.modelo in modelos_disponiveis else 0
        )
        
        st.session_state.api_key = st.text_input(
            "üîë Chave da API",
            value=st.session_state.api_key,
            type="password",
            placeholder="Cole sua chave da API aqui",
            help="Obtenha sua chave em: https://aistudio.google.com/ (Gemini) ou https://platform.openai.com/ (OpenAI)"
        )
        
        # Indicador visual da temperatura
        col_temp1, col_temp2, col_temp3 = st.columns(3)
        with col_temp1:
            if st.session_state.temperatura <= 0.3:
                st.metric("Estilo", "Preciso", delta="Focado")
        with col_temp2:
            if 0.4 <= st.session_state.temperatura <= 0.7:
                st.metric("Estilo", "Balanceado", delta="Equilibrado")
        with col_temp3:
            if st.session_state.temperatura >= 0.8:
                st.metric("Estilo", "Criativo", delta="Variado")
        
        st.markdown("---")
        st.info("""
        **üí° Dicas:**
        - Fa√ßa perguntas espec√≠ficas sobre o ERP Protheus
        - Use termos t√©cnicos para melhores resultados
        - Configure sua chave de API para usar o assistente
        - Ajuste a temperatura conforme sua necessidade
        - Ative a reclassifica√ß√£o IA para respostas mais precisas
        """)
        
        st.markdown("---")
        st.caption("By Evandro Narciso Santos")
    
    # Conte√∫do principal
    st.title("ü§ñ Responde AI TOTVS")
    st.markdown("Sua assistente inteligente para d√∫vidas sobre o **ERP Protheus**")
    
    # Indicador de configura√ß√£o
    ai_provider = "Google Gemini" if st.session_state.use_gemini else "OpenAI"
    temp_desc = "Preciso" if st.session_state.temperatura <= 0.3 else "Balanceado" if st.session_state.temperatura <= 0.7 else "Criativo"
    reclass_desc = "‚úÖ Ativa" if st.session_state.reclassificar_ia else "‚ùå Inativa"
    
    st.caption(f"üîß Configurado: {ai_provider} | Modelo: {st.session_state.modelo} | Score: {st.session_state.min_score} | Temperatura: {st.session_state.temperatura} ({temp_desc}) | Reclassifica√ß√£o IA: {reclass_desc}")
    
    # √Årea de entrada da pergunta
    user_query = st.text_area(
        "**Digite sua pergunta:**",
        placeholder="Ex: Como configurar par√¢metros financeiros no Protheus?",
        height=120,
        help="Descreva sua d√∫vida t√©cnica sobre o ERP Protheus"
    )
    
    # Bot√£o de envio
    col1, col2 = st.columns([1, 4])
    with col1:
        if st.button("üöÄ Enviar Pergunta", type="primary", use_container_width=True):
            if not user_query.strip():
                st.warning("Por favor, digite sua pergunta.")
            else:
                if not st.session_state.api_key:
                    st.error("‚ùå Configure sua chave da API na sidebar para continuar.")
                else:
                    resposta = processar_pergunta(user_query)
                    st.session_state.resposta = resposta
                    st.session_state.mostrar_codigo = False
    
    with col2:
        if st.button("üßπ Limpar", use_container_width=True):
            if 'resposta' in st.session_state:
                del st.session_state.resposta
            st.session_state.mostrar_codigo = False
            st.rerun()
    
    # Exibir resposta se existir
    if 'resposta' in st.session_state and st.session_state.resposta:
        st.markdown("---")
        st.subheader("üìã Resposta:")
        
        # Controles para a resposta
        col_controls1, col_controls2, col_controls3 = st.columns([2, 1, 1])
        
        with col_controls1:
            # Toggle entre visualiza√ß√£o normal e c√≥digo
            if st.button("üìÑ Visualizar como C√≥digo" if not st.session_state.mostrar_codigo else "üìù Visualizar Normal", 
                        key="toggle_view", use_container_width=True):
                st.session_state.mostrar_codigo = not st.session_state.mostrar_codigo
                st.rerun()
        
        with col_controls2:
            # Bot√£o para copiar (usando st.code que tem c√≥pia nativa)
            if st.button("üìã Copiar Resposta", key="copy_btn", use_container_width=True):
                # Mostrar a resposta em formato c√≥digo que permite c√≥pia f√°cil
                st.session_state.mostrar_codigo = True
                st.success("‚úÖ Use Ctrl+C para copiar o texto acima!")
        
        with col_controls3:
            # Bot√£o para baixar
            if st.button("üíæ Baixar", key="download_btn", use_container_width=True):
                st.download_button(
                    label="üì• Clique para baixar",
                    data=st.session_state.resposta,
                    file_name=f"resposta_totvs_{time.strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain",
                    key="download_file"
                )
        
        # Exibir a resposta
        if st.session_state.mostrar_codigo:
            # Modo c√≥digo - f√°cil de copiar
            st.code(st.session_state.resposta, language="text", line_numbers=False)
            st.info("üí° **Dica:** Selecione o texto acima e use Ctrl+C para copiar")
        else:
            # Modo normal - melhor visualiza√ß√£o
            st.write(st.session_state.resposta)

if __name__ == "__main__":
    main()
