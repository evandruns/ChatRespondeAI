import streamlit as st
import os
import re
import urllib.parse
import random
import time
from typing import List, Set, Tuple
import pandas as pd
import requests
from bs4 import BeautifulSoup
from ddgs import DDGS
import cloudscraper
import json
from datetime import datetime

# ---------------------------
# Configura√ß√£o Inicial
# ---------------------------
st.set_page_config(
    page_title="Responde AI TOTVS",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------------------------
# SISTEMA DE CACHE PARA MELHOR PERFORMANCE
# ---------------------------
class CacheManager:
    def __init__(self, ttl=3600):  # 1 hora de cache
        self.cache = {}
        self.ttl = ttl
    
    def get(self, key):
        if key in self.cache:
            data, timestamp = self.cache[key]
            if time.time() - timestamp < self.ttl:
                return data
            else:
                del self.cache[key]
        return None
    
    def set(self, key, value):
        self.cache[key] = (value, time.time())
    
    def clear(self):
        self.cache.clear()

cache = CacheManager()

# ---------------------------
# HEADERS MELHORADOS COM ROTA√á√ÉO DIN√ÇMICA
# ---------------------------
def get_dynamic_headers(url=None):
    """Retorna headers din√¢micos e realistas"""
    user_agents = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:125.0) Gecko/20100101 Firefox/125.0',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36'
    ]
    
    base_headers = {
        'authority': 'centraldeatendimento.totvs.com',
        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        'accept-language': 'pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7',
        'cache-control': 'no-cache',
        'pragma': 'no-cache',
        'sec-ch-ua': '"Google Chrome";v="141", "Not?A_Brand";v="8", "Chromium";v="141"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
        'sec-fetch-dest': 'document',
        'sec-fetch-mode': 'navigate',
        'sec-fetch-site': 'same-origin',
        'upgrade-insecure-requests': '1',
        'user-agent': random.choice(user_agents),
    }
    
    if url:
        base_headers['referer'] = 'https://centraldeatendimento.totvs.com/'
    
    return base_headers

# ---------------------------
# SISTEMA DE REQUISI√á√ïES ROBUSTO
# ---------------------------
def create_advanced_scraper():
    """Cria um scraper avan√ßado com retry autom√°tico"""
    try:
        scraper = cloudscraper.create_scraper(
            browser={
                'browser': 'chrome',
                'platform': 'windows',
                'mobile': False
            },
            delay=10,
        )
        return scraper
    except Exception as e:
        st.warning(f"CloudScraper n√£o dispon√≠vel: {e}. Usando requests.")
        return requests.Session()

scraper = create_advanced_scraper()

def fazer_requisicao_inteligente(url, max_tentativas=3):
    """Sistema inteligente de requisi√ß√µes com m√∫ltiplas estrat√©gias"""
    cache_key = f"req_{hash(url)}"
    cached = cache.get(cache_key)
    if cached:
        return cached
    
    for tentativa in range(max_tentativas):
        try:
            # Delay progressivo entre tentativas
            if tentativa > 0:
                delay = tentativa * 2 + random.uniform(1, 3)
                time.sleep(delay)
            
            headers = get_dynamic_headers(url)
            
            # Tentar com CloudScraper primeiro
            response = scraper.get(url, headers=headers, timeout=25)
            
            if response.status_code == 200:
                # Verificar se n√£o √© uma p√°gina de bloqueio
                content_lower = response.text.lower()
                if not any(term in content_lower for term in ['access denied', 'blocked', 'bot detected', 'captcha']):
                    cache.set(cache_key, response)
                    return response
            
            # Se falhou, tentar com requests simples
            session = requests.Session()
            alt_headers = headers.copy()
            alt_headers['user-agent'] = random.choice([
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:125.0) Gecko/20100101 Firefox/125.0'
            ])
            
            response = session.get(url, headers=alt_headers, timeout=20)
            if response.status_code == 200:
                cache.set(cache_key, response)
                return response
                
        except requests.exceptions.Timeout:
            continue
        except requests.exceptions.ConnectionError:
            continue
        except Exception as e:
            continue
    
    return None

# ---------------------------
# SISTEMA DE BUSCA APRIMORADO
# ---------------------------
def buscar_via_api_zendesk(query, max_results=5):
    """Busca usando a API oficial do Zendesk (m√©todo mais confi√°vel)"""
    cache_key = f"api_search_{hash(query)}"
    cached = cache.get(cache_key)
    if cached:
        return cached
    
    try:
        base_url = "https://centraldeatendimento.totvs.com/api/v2/help_center/pt-br/articles/search"
        params = {'query': query, 'per_page': max_results}
        
        headers = get_dynamic_headers()
        headers['accept'] = 'application/json'
        
        response = requests.get(base_url, params=params, headers=headers, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            articles = data.get('results', [])
            
            links = []
            for article in articles:
                url = article.get('html_url')
                if url and url not in links:
                    links.append(url)
            
            cache.set(cache_key, links)
            return links
            
    except Exception as e:
        pass
    
    return []

def extrair_conteudo_via_api(url):
    """Extrai conte√∫do via API - m√©todo mais confi√°vel"""
    try:
        article_id = re.search(r'/articles/(\d+)', url)
        if not article_id:
            return None
            
        article_id = article_id.group(1)
        api_url = f"https://centraldeatendimento.totvs.com/api/v2/help_center/pt-br/articles/{article_id}"
        
        headers = get_dynamic_headers()
        headers['accept'] = 'application/json'
        
        response = requests.get(api_url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            article = data.get('article', {})
            
            body = article.get('body', '')
            title = article.get('title', '')
            
            soup = BeautifulSoup(body, 'html.parser')
            text = soup.get_text(separator=' ', strip=True)
            
            full_content = f"{title}\n\n{text}"
            return clean_text(full_content)[:6000]
            
    except Exception:
        pass
    
    return None

# ---------------------------
# STOP WORDS E PR√â-PROCESSAMENTO (MELHORADO)
# ---------------------------
STOP_WORDS = {
    "bom dia", "boa tarde", "boa noite", "ol√°", "att", "atenciosamente",
    "cumprimentos", "obrigado", "obrigada", "prezado", "prezada",
    "caro", "cara", "senhor", "senhora", "ola", "oi", "sauda√ß√µes",
    "tudo bem", "tudo bem?", "amigo", "amiga", "por favor",
    "grato", "grata", "cordialmente", "abra√ßo", "abs", "ok", "entendi",
    "obg", "vlw", "por favor", "favor", "gostaria", "queria", "saber"
}

PALAVRAS_TECNICAS = {
    'erp', 'sql', 'api', 'xml', 'json', 'tss', 'nt', 'danfe', 'nfe', 'cte',
    'mde', 'sped', 'ecd', 'ecf', 'efd', 'protheus', 'fluig', 'rm', 'log',
    'fis', 'fat', 'crm', 'com', 'tms', 'wms', 'bi', 'linx', 'datasul'
}

def clean_query(query: str) -> str:
    """Limpa e otimiza a query para busca"""
    if not query:
        return ""
    
    # Remover caracteres especiais mas manter acentos
    query = re.sub(r'[^\w\s√°√†√¢√£√©√®√™√≠√Ø√≥√¥√µ√∂√∫√ß√±√Å√Ä√Ç√£√â√à√ä√ç√è√ì√î√ï√ñ√ö√á√ë-]', ' ', query)
    query = query.lower().strip()
    
    # Remover stop words mas manter palavras t√©cnicas
    parts = query.split()
    keep = []
    
    for p in parts:
        p_clean = p.strip()
        if (p_clean not in STOP_WORDS and len(p_clean) >= 2) or p_clean in PALAVRAS_TECNICAS:
            keep.append(p_clean)
    
    # Adicionar "Protheus" se n√£o estiver presente e for uma consulta t√©cnica
    if keep and "protheus" not in " ".join(keep).lower():
        termos_tecnicos = any(term in " ".join(keep).lower() for term in 
                            ['configurar', 'par√¢metro', 'erro', 'funcionalidade', 'm√≥dulo'])
        if termos_tecnicos:
            keep.append("protheus")
    
    return " ".join(keep)

def clean_text(text: str) -> str:
    """Limpa texto extra√≠do com algoritmos melhorados"""
    if not text or pd.isna(text):
        return ""
    
    # Remover caracteres nulos e problemas de encoding
    text = text.replace("\0", " ").replace("\r", " ").replace("\t", " ")
    
    # Remover padr√µes comuns de lixo
    patterns = [
        r'Anexo\(s\):.*',
        r'Compartilhar:.*',
        r'Coment√°rios.*',
        r'Artigo criado.*Artigo atualizado.*',
        r'¬©\s*\d{4}.*TOTVS',
        r'https?://\S+',
        r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b'
    ]
    
    for pattern in patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.DOTALL)
    
    # Remover HTML tags
    text = re.sub(r'<[^>]*>', ' ', text)
    
    # Normalizar espa√ßos
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def tem_video_ou_anexo(query: str) -> bool:
    """Verifica se a query se refere a conte√∫do multim√≠dia"""
    padroes = [
        r"\banexo\b", r"\banexos\b", r"\banexado\b", r"\banexada\b",
        r"\bv[√≠i]deo\b", r"\bv[√≠i]deos\b", r"\bgrava√ß[√£a]o\b",
        r"\bprint\b", r"\bimagem\b", r"\bscreenshot\b", r"\bfoto\b",
        r"\bpdf\b", r"\barquivo\b", r"\bdownload\b"
    ]
    query_lower = query.lower()
    return any(re.search(p, query_lower) for p in padroes)

# ---------------------------
# SISTEMA DE EXTRA√á√ÉO MELHORADO
# ---------------------------
def extrair_conteudo_pagina(url: str) -> str:
    """Extrai conte√∫do com m√∫ltiplas estrat√©gias"""
    if '/search?' in url:
        return "P√°gina de pesquisa - conte√∫do n√£o extra√≠do"

    # Tentar via API primeiro (m√©todo mais confi√°vel)
    conteudo_api = extrair_conteudo_via_api(url)
    if conteudo_api:
        return conteudo_api

    # Fallback para scraping tradicional
    try:
        response = fazer_requisicao_inteligente(url)
        
        if not response:
            return f"‚ùå N√£o foi poss√≠vel acessar: {url}"
            
        if response.status_code != 200:
            return f"Erro HTTP {response.status_code}: {url}"

        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remover elementos desnecess√°rios
        for element in soup(['script', 'style', 'nav', 'footer', 'header', 'aside', 'form', 'iframe']):
            element.decompose()
        
        # Estrat√©gias de sele√ß√£o melhoradas
        content_selectors = [
            "article",
            ".article-body",
            ".article-content", 
            "main",
            ".content",
            ".post-content",
            "[role='main']",
            ".help-center-content"
        ]
        
        content = None
        for selector in content_selectors:
            content = soup.select_one(selector)
            if content:
                break
        
        # Limpar elementos espec√≠ficos
        if content:
            cleanup_selectors = [
                '.article-meta', '.article-info', '.article-votes',
                '.comments', '.share-buttons', '.breadcrumb',
                '.related-articles', '.article-attachments'
            ]
            
            for selector in cleanup_selectors:
                for element in content.select(selector):
                    element.decompose()
            
            text = content.get_text(separator=' ', strip=True)
        else:
            # Fallback estrat√©gico
            body = soup.find('body')
            text = body.get_text(separator=' ', strip=True) if body else soup.get_text(separator=' ', strip=True)
        
        cleaned_text = clean_text(text)
        return cleaned_text[:6000] if cleaned_text else "Conte√∫do n√£o encontrado"
        
    except Exception as e:
        return f"Erro na extra√ß√£o: {str(e)}"

def pesquisar_interna_totvs(query: str, limit: int = 5) -> List[str]:
    """Pesquisa interna com fallbacks"""
    cache_key = f"internal_search_{hash(query)}"
    cached = cache.get(cache_key)
    if cached:
        return cached
    
    base = "https://centraldeatendimento.totvs.com"
    search_url = f"{base}/hc/pt-br/search?query={urllib.parse.quote(query)}"
    
    links = []
    try:
        response = fazer_requisicao_inteligente(search_url)
        
        if response and response.status_code == 200:
            soup = BeautifulSoup(response.content, "html.parser")
            
            # M√∫ltiplos seletores para robustez
            selectors = [
                "a[href*='/articles/']",
                ".search-result a",
                ".article-list a",
                ".article-link"
            ]
            
            for selector in selectors:
                for a in soup.select(selector):
                    href = a.get("href", "")
                    if href:
                        if href.startswith("/"):
                            href = base + href
                        elif not href.startswith("http"):
                            href = base + "/" + href.lstrip("/")
                            
                        if href.startswith(base) and "/articles/" in href and href not in links:
                            links.append(href)
                            
                    if len(links) >= limit:
                        break
                if len(links) >= limit:
                    break
                    
    except Exception as e:
        pass
    
    cache.set(cache_key, links)
    return links

def buscar_documentacao_totvs(query: str, max_links: int = 5) -> List[str]:
    """Sistema h√≠brido de busca com m√∫ltiplas fontes"""
    cache_key = f"search_{hash(query)}"
    cached = cache.get(cache_key)
    if cached:
        return cached
    
    cleaned = clean_query(query)
    if not cleaned:
        return []
    
    found = []
    seen = set()
    
    # Estrat√©gia 1: API Zendesk (mais confi√°vel)
    api_links = buscar_via_api_zendesk(cleaned, max_links)
    for url in api_links:
        if url not in seen:
            found.append(url)
            seen.add(url)
    
    # Estrat√©gia 2: DuckDuckGo
    if len(found) < max_links:
        try:
            search_query = f"site:centraldeatendimento.totvs.com {cleaned}"
            with DDGS() as ddgs:
                for r in ddgs.text(search_query, max_results=10):
                    url = r.get("href", "")
                    if (url.startswith("https://centraldeatendimento.totvs.com") and 
                        "/articles/" in url and url not in seen):
                        found.append(url)
                        seen.add(url)
                    if len(found) >= max_links:
                        break
        except Exception as e:
            pass
    
    # Estrat√©gia 3: Pesquisa interna
    if len(found) < max_links:
        interna_links = pesquisar_interna_totvs(cleaned, max_links - len(found))
        for url in interna_links:
            if url not in seen:
                found.append(url)
                seen.add(url)
    
    # Fallback final
    if not found:
        found = [f"https://centraldeatendimento.totvs.com/hc/pt-br/search?query={urllib.parse.quote(cleaned)}"]
    
    cache.set(cache_key, found)
    return found[:max_links]

# ---------------------------
# SISTEMA DE RELEV√ÇNCIA MELHORADO
# ---------------------------
def pontuar_relevancia(texto: str, query: str) -> float:
    """Sistema de pontua√ß√£o de relev√¢ncia melhorado"""
    if not texto or not query:
        return 0.0
    
    tokens_query = set(clean_query(query).split())
    tokens_texto = set(texto.lower().split())
    
    if not tokens_query or not tokens_texto:
        return 0.0
    
    # Pontua√ß√£o baseada na interse√ß√£o
    intersection = tokens_query & tokens_texto
    base_score = len(intersection) / len(tokens_query)
    
    # B√¥nus para correspond√™ncias exatas
    exact_matches = sum(1 for token in tokens_query if token in texto.lower())
    exact_bonus = exact_matches * 0.1
    
    # B√¥nus para palavras t√©cnicas
    tech_bonus = sum(0.05 for token in intersection if token in PALAVRAS_TECNICAS)
    
    final_score = min(base_score + exact_bonus + tech_bonus, 1.0)
    return final_score

# ---------------------------
# SISTEMA IA MELHORADO COM TRATAMENTO DE ERROS
# ---------------------------
def reclassificar_artigos_ia(artigos: List[Tuple[float, str, str]], query: str, use_gemini: bool, api_key: str, modelo: str) -> List[Tuple[float, str, str]]:
    """Usa IA para reclassificar os artigos por relev√¢ncia"""
    if not artigos or len(artigos) <= 1:
        return artigos
    
    cache_key = f"reclass_{hash(query + ''.join(url for _, url, _ in artigos))}"
    cached = cache.get(cache_key)
    if cached:
        return cached
    
    try:
        artigos_info = []
        for score, url, conteudo in artigos:
            titulo = url.split('/')[-1].replace('-', ' ')[:100]
            preview = conteudo[:200] + "..." if conteudo and len(conteudo) > 50 else "Conte√∫do n√£o dispon√≠vel"
            artigos_info.append(f"URL: {url}\nT√≠tulo: {titulo}\nConte√∫do: {preview}\n---")
        
        artigos_texto = "\n".join(artigos_info)
        
        if use_gemini:
            resposta = reclassificar_gemini(query, artigos_texto, modelo, api_key)
        else:
            resposta = reclassificar_openai(query, artigos_texto, modelo, api_key)
        
        artigos_ordenados = processar_resposta_reclassificacao(resposta, artigos)
        
        if artigos_ordenados:
            cache.set(cache_key, artigos_ordenados)
            return artigos_ordenados
        else:
            resultado = sorted(artigos, reverse=True, key=lambda x: x[0])
            cache.set(cache_key, resultado)
            return resultado
            
    except Exception as e:
        st.error(f"Erro na reclassifica√ß√£o por IA: {e}")
        resultado = sorted(artigos, reverse=True, key=lambda x: x[0])
        cache.set(cache_key, resultado)
        return resultado

def reclassificar_gemini(query: str, artigos_texto: str, model: str, api_key: str) -> str:
    """Reclassifica artigos usando Gemini com tratamento robusto de erros"""
    try:
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        
        # Configura√ß√£o de seguran√ßa para evitar respostas bloqueadas
        safety_settings = [
            {
                "category": "HARM_CATEGORY_HARASSMENT",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_HATE_SPEECH", 
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "threshold": "BLOCK_NONE"
            }
        ]
        
        prompt = f"""
        Analise estes artigos da documenta√ß√£o TOTVS e ordene-os por relev√¢ncia para a pergunta do usu√°rio.
        
        PERGUNTA DO USU√ÅRIO: {query}
        
        ARTIGOS ENCONTRADOS:
        {artigos_texto}
        
        INSTRU√á√ïES:
        1. Analise cada artigo em rela√ß√£o √† pergunta
        2. Ordene do MAIS RELEVANTE para o MENOS RELEVANTE  
        3. Retorne APENAS os URLs em ordem de relev√¢ncia, um por linha
        4. N√£o inclua explica√ß√µes, apenas a lista ordenada de URLs
        5. Se n√£o puder determinar a relev√¢ncia, retorne os URLs na ordem original
        
        URLs ORDENADOS:
        """
        
        # Usar modelo mais est√°vel
        if model not in ["gemini-2.5-flash", "gemini-2.5-pro"]:
            model = "gemini-2.5-flash"
            
        gemini_model = genai.GenerativeModel(
            model_name=model,
            safety_settings=safety_settings,
            generation_config={
                "temperature": 0.0,
                "max_output_tokens": 500,
            }
        )
        
        response = gemini_model.generate_content([prompt])
        
        # Tratamento robusto da resposta
        if response and response.parts:
            return response.text.strip()
        elif response and response.candidates:
            # Tentar extrair texto dos candidatos
            for candidate in response.candidates:
                if candidate.content and candidate.content.parts:
                    return candidate.content.parts[0].text.strip()
        
        return ""  # Retorna string vazia em caso de erro
        
    except Exception as e:
        st.warning(f"Aviso Gemini: {e}")
        return ""  # Retorna string vazia em caso de erro

def reclassificar_openai(query: str, artigos_texto: str, model: str, api_key: str) -> str:
    """Reclassifica artigos usando OpenAI"""
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
        
        prompt = f"""
        Analise estes artigos da documenta√ß√£o TOTVS e ordene-os por relev√¢ncia para a pergunta do usu√°rio.
        
        PERGUNTA DO USU√ÅRIO: {query}
        
        ARTIGOS ENCONTRADOS:
        {artigos_texto}
        
        INSTRU√á√ïES:
        1. Analise cada artigo em rela√ß√£o √† pergunta
        2. Ordene do MAIS RELEVANTE para o MENOS RELEVANTE
        3. Retorne APENAS os URLs em ordem de relev√¢ncia, um por linha
        4. N√£o inclua explica√ß√µes, apenas a lista ordenada de URLs
        """
        
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "Voc√™ √© um especialista em classificar documenta√ß√£o t√©cnica por relev√¢ncia."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.0,
            max_tokens=500,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        raise Exception(f"Erro OpenAI: {e}")

def processar_resposta_reclassificacao(resposta_ia: str, artigos_originais: List[Tuple[float, str, str]]) -> List[Tuple[float, str, str]]:
    """Processa a resposta da IA e reordena os artigos"""
    if not resposta_ia:
        return []
    
    # Extrair URLs da resposta
    urls_ordenados = []
    for linha in resposta_ia.split('\n'):
        linha = linha.strip()
        if linha.startswith('http'):
            urls_ordenados.append(linha)
    
    # Criar mapa de artigos por URL
    artigo_por_url = {url: (score, url, conteudo) for score, url, conteudo in artigos_originais}
    
    # Reordenar baseado na classifica√ß√£o da IA
    artigos_ordenados = []
    for url in urls_ordenados:
        if url in artigo_por_url:
            artigos_ordenados.append(artigo_por_url[url])
    
    # Adicionar quaisquer artigos que n√£o foram classificados pela IA
    urls_adicionados = set(urls_ordenados)
    for artigo in artigos_originais:
        if artigo[1] not in urls_adicionados:
            artigos_ordenados.append(artigo)
    
    return artigos_ordenados

def formatar_links_saiba_mais(links: List[str]) -> str:
    """Formata os links para a se√ß√£o Saiba Mais"""
    if not links:
        return ""
    
    padroes_de_remocao = ["-Cross", "-CROSS", "-RH", "-MP", "-Log√≠stica", "-Framework", "-LOG", "-FIN", "-FAT", "-CRM"]
    
    links_formatados = []
    for link in links:
        link_limpo = link
        for padrao in padroes_de_remocao:
            posicao = link.find(padrao)
            if posicao != -1:
                link_limpo = link[:posicao]
                break
        links_formatados.append(link_limpo)
    
    # Remover duplicatas mantendo a ordem
    links_unicos = []
    for link in links_formatados:
        if link not in links_unicos:
            links_unicos.append(link)
    
    # Formatar a se√ß√£o Saiba Mais
    saiba_mais = "\n\n**üîó Saiba mais:**\n"
    for i, link in enumerate(links_unicos[:5], 1):  # Limitar a 5 links
        saiba_mais += f"{i}. {link}\n"
    
    return saiba_mais

def get_ai_response(query: str, context: str, fontes: List[str], modelo: str, use_gemini: bool, api_key: str, temperatura: float):
    """Fun√ß√£o unificada que escolhe entre Gemini e ChatGPT com tratamento robusto"""
    
    # Filtrar contexto removendo mensagens de erro
    if "erro 403" in context.lower() or "acesso negado" in context.lower():
        context = "Conte√∫do n√£o dispon√≠vel devido a restri√ß√µes de acesso."
    
    if not context or not context.strip() or context == "Conte√∫do n√£o dispon√≠vel devido a restri√ß√µes de acesso.":
        return "N√£o encontrei essa informa√ß√£o na documenta√ß√£o oficial devido a restri√ß√µes de acesso."

    try:
        if use_gemini:
            return get_gemini_response_robusto(query, context, fontes, modelo, api_key, temperatura)
        else:
            return get_chatgpt_response(query, context, fontes, modelo, api_key, temperatura)
    except Exception as e:
        return f"Erro ao processar a resposta: {str(e)}"

def get_gemini_response_robusto(query: str, context: str, fontes: List[str], model: str, api_key: str, temperatura: float):
    """Vers√£o robusta do Gemini com tratamento completo de erros"""
    try:
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        
        # Configura√ß√µes de seguran√ßa relaxadas
        safety_settings = [
            {
                "category": "HARM_CATEGORY_HARASSMENT",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_HATE_SPEECH",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "threshold": "BLOCK_NONE"
            }
        ]
        
        generation_config = {
            "temperature": min(temperatura, 0.7),  # Limitar temperatura para evitar problemas
            "top_p": 0.8,
            "top_k": 40,
            "max_output_tokens": 1024,
        }
        
        # Usar modelo mais est√°vel
        if model not in ["gemini-2.5-flash", "gemini-2.5-pro"]:
            model = "gemini-2.5-flash"
        
        gemini_model = genai.GenerativeModel(
            model_name=model,
            generation_config=generation_config,
            safety_settings=safety_settings
        )
        
        system_prompt = (
            "Voc√™ √© um analista de suporte especializado no ERP Protheus da TOTVS.\n"
            "Responda de forma t√©cnica, precisa e baseada exclusivamente no contexto fornecido.\n"
            "- Se a informa√ß√£o n√£o estiver no contexto, responda apenas: \"N√£o encontrei essa informa√ß√£o na documenta√ß√£o oficial\".\n"
            "- Seja objetivo e inclua passos acion√°veis quando aplic√°vel.\n"
            "- N√ÉO inclua a se√ß√£o 'Fontes consultadas' no final - isso ser√° adicionado automaticamente.\n"
        )

        user_content = (
            f"{system_prompt}\n\n"
            f"PERGUNTA DO USU√ÅRIO:\n{query}\n\n"
            f"CONTE√öDO EXTRA√çDO:\n{context}\n\n"
            "Fontes dispon√≠veis:\n" + "\n".join(fontes)
        )

        response = gemini_model.generate_content([user_content])
        
        # Tratamento robusto da resposta
        if response and response.parts:
            return response.text.strip()
        elif response and response.candidates:
            for candidate in response.candidates:
                if candidate.content and candidate.content.parts:
                    return candidate.content.parts[0].text.strip()
        
        # Fallback se a resposta estiver vazia
        return "N√£o foi poss√≠vel gerar uma resposta para esta consulta."
        
    except Exception as e:
        return f"Erro ao processar a solicita√ß√£o: {str(e)}"

def get_chatgpt_response(query: str, context: str, fontes: List[str], model: str, api_key: str, temperatura: float):
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
        
        system_prompt = (
            "Voc√™ √© um analista de suporte especializado no ERP Protheus da TOTVS.\n"
            "Responda de forma t√©cnica, precisa e baseada exclusivamente no contexto fornecido.\n"
            "- Se a informa√ß√£o n√£o estiver no contexto, responda apenas: \"N√£o encontrei essa informa√ß√£o na documenta√ß√£o oficial\".\n"
            "- Seja objetivo e inclua passos acion√°veis quando aplic√°vel.\n"
            "- N√ÉO inclua a se√ß√£o 'Fontes consultadas' no final - isso ser√° adicionado automaticamente.\n"
        )
        
        user_content = f"PERGUNTA DO USU√ÅRIO:\n{query}\n\nCONTE√öDO EXTRA√çDO:\n{context}\n\nFontes dispon√≠veis:\n" + "\n".join(fontes)

        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content},
            ],
            temperature=temperatura,
            max_tokens=512,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"Erro ao gerar resposta com OpenAI: {e}"

# ---------------------------
# INTERFACE STREAMLIT MELHORADA
# ---------------------------
def inicializar_session_state():
    """Inicializa as vari√°veis de session state"""
    defaults = {
        'min_score': 0.3,
        'use_gemini': True,
        'modelo': "gemini-2.5-flash", 
        'api_key': "",
        'temperatura': 0.1,
        'mostrar_codigo': False,
        'reclassificar_ia': True,
        'cache_enabled': True,
        'historico': []
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def atualizar_lista_modelos():
    """Atualiza a lista de modelos baseado na escolha Gemini/OpenAI"""
    if st.session_state.use_gemini:
        modelos_disponiveis = ["gemini-2.5-flash", "gemini-2.5-pro"]
        if st.session_state.modelo not in modelos_disponiveis:
            st.session_state.modelo = "gemini-2.5-flash"
    else:
        modelos_disponiveis = ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"]
        if not any(model in st.session_state.modelo for model in ["gpt", "openai"]):
            st.session_state.modelo = "gpt-4o-mini"
    return modelos_disponiveis

def adicionar_ao_historico(pergunta, resposta):
    """Adiciona intera√ß√£o ao hist√≥rico"""
    if 'historico' not in st.session_state:
        st.session_state.historico = []
    
    st.session_state.historico.append({
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'pergunta': pergunta,
        'resposta': resposta[:500] + "..." if len(resposta) > 500 else resposta
    })
    
    # Manter apenas os √∫ltimos 10 itens
    if len(st.session_state.historico) > 10:
        st.session_state.historico = st.session_state.historico[-10:]

def processar_pergunta(user_query: str):
    """Processa a pergunta do usu√°rio e retorna a resposta"""
    # Verificar se a API key foi configurada
    if not st.session_state.api_key:
        return "Erro: Chave da API n√£o configurada. Por favor, configure sua chave na sidebar."
    
    cleaned_query = clean_query(user_query)
    if not cleaned_query:
        return "N√£o foi poss√≠vel processar a pergunta."

    if tem_video_ou_anexo(user_query):
        return "Pergunta cont√©m refer√™ncia a v√≠deo ou anexo. N√£o ser√° feita busca autom√°tica na documenta√ß√£o."
    
    try:
        # Buscar links
        with st.status("Buscando na documenta√ß√£o TOTVS...", expanded=True) as status:
            status.write("üîç Procurando artigos relevantes...")
            links = buscar_documentacao_totvs(user_query, max_links=5)
            
            if not links:
                return "N√£o foram encontrados artigos relevantes na documenta√ß√£o TOTVS."
            
            status.write(f"üìö Encontrados {len(links)} artigos. Extraindo conte√∫do...")
            contexto_scores = []
            
            # Extrair conte√∫do dos links
            for i, link in enumerate(links):
                status.write(f"üìñ Lendo artigo {i+1}/{len(links)}...")
                texto = extrair_conteudo_pagina(link)
                score = pontuar_relevancia(texto, user_query)
                contexto_scores.append((score, link, texto))

            # Reclassifica√ß√£o inteligente por IA
            if st.session_state.reclassificar_ia and len(contexto_scores) > 1:
                status.write("üß† Reclassificando artigos por relev√¢ncia...")
                contexto_scores = reclassificar_artigos_ia(
                    contexto_scores, 
                    user_query, 
                    st.session_state.use_gemini,
                    st.session_state.api_key,
                    st.session_state.modelo
                )
            else:
                # Ordena√ß√£o tradicional por score
                contexto_scores.sort(reverse=True, key=lambda x: x[0])
            
            status.write("ü§ñ Gerando resposta com IA...")
            
            # Usar os 3 artigos mais relevantes para o contexto
            artigos_relevantes = contexto_scores[:3]
            contexto_combinado = "\n\n".join([conteudo for _, _, conteudo in artigos_relevantes if conteudo.strip()])
            
            # Gerar resposta
            if not contexto_combinado.strip():
                resposta_final = "Aten√ß√£o: n√£o foi poss√≠vel validar essa informa√ß√£o espec√≠fica na documenta√ß√£o oficial."
            elif contexto_scores[0][0] < st.session_state.min_score:
                resposta_final = "Observa√ß√£o: essa consulta aborda um ponto n√£o detalhado na documenta√ß√£o. A resposta √© baseada em conhecimento geral.\n\n"
                resposta_final += get_ai_response(
                    user_query, 
                    contexto_combinado, 
                    [link for _, link, _ in artigos_relevantes], 
                    st.session_state.modelo,
                    st.session_state.use_gemini,
                    st.session_state.api_key,
                    st.session_state.temperatura
                )
            else:
                resposta_final = get_ai_response(
                    user_query, 
                    contexto_combinado, 
                    [link for _, link, _ in artigos_relevantes], 
                    st.session_state.modelo,
                    st.session_state.use_gemini,
                    st.session_state.api_key,
                    st.session_state.temperatura
                )
            
            # Adicionar se√ß√£o "Saiba mais" se a resposta for v√°lida
            mensagens_erro = [
                "n√£o foi poss√≠vel validar essa informa√ß√£o espec√≠fica",
                "n√£o encontrei essa informa√ß√£o na documenta√ß√£o oficial",
                "conte√∫do n√£o dispon√≠vel devido a restri√ß√µes de acesso",
                "erro ao processar",
                "n√£o foi poss√≠vel gerar"
            ]
            
            resposta_valida = not any(erro in resposta_final.lower() for erro in mensagens_erro)
            
            if resposta_valida and links:
                saiba_mais = formatar_links_saiba_mais([link for _, link, _ in contexto_scores[:5]])
                resposta_final += saiba_mais
            
            status.update(label="Processamento completo!", state="complete")
            
        # Adicionar ao hist√≥rico
        adicionar_ao_historico(user_query, resposta_final)
        return resposta_final

    except Exception as e:
        return f"Ocorreu um erro durante o processamento: {str(e)}"

def main():
    # Inicializar session state
    inicializar_session_state()
    
    # Sidebar para configura√ß√µes
    with st.sidebar:
        st.header("‚öôÔ∏è Configura√ß√µes Avan√ßadas")
        
        # Configura√ß√µes b√°sicas
        st.session_state.use_gemini = st.checkbox(
            "Usar Google Gemini", 
            value=st.session_state.use_gemini,
            help="Desmarque para usar OpenAI"
        )
        
        modelos_disponiveis = atualizar_lista_modelos()
        
        # Configura√ß√µes de performance
        st.subheader("üöÄ Performance")
        
        st.session_state.cache_enabled = st.checkbox(
            "Ativar Cache", 
            value=st.session_state.cache_enabled,
            help="Melhora performance armazenando resultados temporariamente"
        )
        
        if st.button("üßπ Limpar Cache"):
            cache.clear()
            st.success("Cache limpo!")
        
        st.session_state.reclassificar_ia = st.checkbox(
            "Reclassifica√ß√£o por IA", 
            value=st.session_state.reclassificar_ia,
            help="Usa IA para ordenar resultados por relev√¢ncia"
        )
        
        st.session_state.min_score = st.slider(
            "Score M√≠nimo de Relev√¢ncia",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.min_score,
            step=0.05,
            help="Valores mais baixos retornam mais resultados"
        )
        
        st.session_state.temperatura = st.slider(
            "Temperatura da IA",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.temperatura,
            step=0.1,
            help="0 = preciso, 1 = criativo"
        )
        
        # Modelo e API
        st.session_state.modelo = st.selectbox(
            "Modelo de IA",
            options=modelos_disponiveis,
            index=modelos_disponiveis.index(st.session_state.modelo)
        )
        
        st.session_state.api_key = st.text_input(
            "Chave da API",
            value=st.session_state.api_key,
            type="password",
            placeholder="Cole sua chave da API aqui"
        )
        
        # Hist√≥rico
        if st.session_state.get('historico'):
            st.subheader("üìö Hist√≥rico")
            for i, item in enumerate(reversed(st.session_state.historico[-5:])):
                with st.expander(f"{item['timestamp']} - {item['pergunta'][:50]}..."):
                    st.write(f"**P:** {item['pergunta']}")
                    st.write(f"**R:** {item['resposta']}")
        
        st.markdown("---")
        st.info("""
        **üí° Dicas:**
        - Use termos t√©cnicos espec√≠ficos
        - Score 0.2-0.4 para mais resultados
        - Ative o cache para melhor performance
        - Temperatura 0.1-0.3 para respostas precisas
        """)
        
        st.markdown("---")
        st.caption("By Evandro Narciso Santos")
    
    # Conte√∫do principal
    st.title("ü§ñ Responde AI TOTVS")
    st.markdown("Sua assistente inteligente para d√∫vidas sobre o **ERP Protheus**")
    
    # Indicador de configura√ß√£o
    ai_provider = "Google Gemini" if st.session_state.use_gemini else "OpenAI"
    temp_desc = "Preciso" if st.session_state.temperatura <= 0.3 else "Balanceado" if st.session_state.temperatura <= 0.7 else "Criativo"
    reclass_desc = "‚úÖ Ativa" if st.session_state.reclassificar_ia else "‚ùå Inativa"
    cache_desc = "‚úÖ Ativo" if st.session_state.cache_enabled else "‚ùå Inativo"
    
    st.caption(f"üîß Configurado: {ai_provider} | Modelo: {st.session_state.modelo} | Score: {st.session_state.min_score} | Temperatura: {st.session_state.temperatura} ({temp_desc}) | Reclassifica√ß√£o IA: {reclass_desc} | Cache: {cache_desc}")
    
    # √Årea de entrada da pergunta
    user_query = st.text_area(
        "**Digite sua pergunta:**",
        placeholder="Ex: Como configurar par√¢metros financeiros no Protheus?",
        height=150,
        help="Descreva sua d√∫vida t√©cnica sobre o ERP Protheus"
    )
    
    # Bot√£o de envio
    col1, col2 = st.columns([1, 4])
    with col1:
        if st.button("üöÄ Enviar Pergunta", type="primary", use_container_width=True):
            if not user_query.strip():
                st.warning("Por favor, digite sua pergunta.")
            else:
                if not st.session_state.api_key:
                    st.error("‚ùå Configure sua chave da API na sidebar para continuar.")
                else:
                    resposta = processar_pergunta(user_query)
                    st.session_state.resposta = resposta
                    st.session_state.mostrar_codigo = False
    
    with col2:
        if st.button("üßπ Limpar", use_container_width=True):
            if 'resposta' in st.session_state:
                del st.session_state.resposta
            st.session_state.mostrar_codigo = False
            st.rerun()
    
    # Exibir resposta se existir
    if 'resposta' in st.session_state and st.session_state.resposta:
        st.markdown("---")
        st.subheader("üìã Resposta:")
        
        # Controles para a resposta
        col_controls1, col_controls2, col_controls3 = st.columns([2, 1, 1])
        
        with col_controls1:
            # Toggle entre visualiza√ß√£o normal e c√≥digo
            if st.button("üìÑ Visualizar como C√≥digo" if not st.session_state.mostrar_codigo else "üìù Visualizar Normal", 
                        key="toggle_view", use_container_width=True):
                st.session_state.mostrar_codigo = not st.session_state.mostrar_codigo
                st.rerun()
        
        with col_controls2:
            # Bot√£o para copiar (usando st.code que tem c√≥pia nativa)
            if st.button("üìã Copiar Resposta", key="copy_btn", use_container_width=True):
                # Mostrar a resposta em formato c√≥digo que permite c√≥pia f√°cil
                st.session_state.mostrar_codigo = True
                st.success("‚úÖ Use Ctrl+C para copiar o texto acima!")
        
        with col_controls3:
            # Bot√£o para baixar
            if st.button("üíæ Baixar", key="download_btn", use_container_width=True):
                st.download_button(
                    label="üì• Clique para baixar",
                    data=st.session_state.resposta,
                    file_name=f"resposta_totvs_{time.strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain",
                    key="download_file"
                )
        
        # Exibir a resposta
        if st.session_state.mostrar_codigo:
            # Modo c√≥digo - f√°cil de copiar
            st.code(st.session_state.resposta, language="text", line_numbers=False)
            st.info("üí° **Dica:** Selecione o texto acima e use Ctrl+C para copiar")
        else:
            # Modo normal - melhor visualiza√ß√£o
            st.write(st.session_state.resposta)

if __name__ == "__main__":
    main()
